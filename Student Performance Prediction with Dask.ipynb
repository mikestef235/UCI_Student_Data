{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Python Module Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "\n",
    "Using the UCI student-performance dataset, I will demonstrate several of Dask's best features. At a high level, Dask allows for a user to scale the machine learning and data structure packages within Python to multi-core computers and distributed computing clusters. There are three main advantages to Dask...\n",
    "1. It can store data larger than what fits in RAM. \n",
    "2. It executes computations in parallel.\n",
    "3. It includes a task scheduler.\n",
    "\n",
    "The specific objectives are as follows...\n",
    "1. Demonstrate delayed dask execution (reads, aggregations, etc...)\n",
    "2. Demonstrate Dask reading in multiple files at once.\n",
    "3. Construct 3 dask machine learning models\n",
    "    - Linear Regression\n",
    "    - Random Forrest\n",
    "    - Kmeans Clustering\n",
    "4. Use dask grid search to identify ideal parameters in parallel\n",
    "\n",
    "From a practical standpoint, users experienced with Pandas and Sci-kit learn should be able to pick up and implement this package rather quickly.\n",
    "\n",
    "__Resources:__\n",
    "Location of dataset: https://archive.ics.uci.edu/ml/datasets/student+performance\n",
    "\n",
    "__Attribute Information:__\n",
    "1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) \n",
    "2. sex - student's sex (binary: 'F' - female or 'M' - male) \n",
    "3. age - student's age (numeric: from 15 to 22) \n",
    "4. address - student's home address type (binary: 'U' - urban or 'R' - rural) \n",
    "5. famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) \n",
    "6. Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart) \n",
    "7. Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary e.ducation or 4 â€“ higher education) \n",
    "8. Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary e.ducation or 4 â€“ higher education) \n",
    "9. Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') \n",
    "10. Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), '.at_home' or 'other') \n",
    "11. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') \n",
    "12. guardian - student's guardian (nominal: 'mother', 'father' or 'other') \n",
    "13. traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) \n",
    "14. studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) \n",
    "15. failures - number of past class failures (numeric: n if 1<=n<3, else 4) \n",
    "16. schoolsup - extra educational support (binary: yes or no) \n",
    "17. famsup - family educational support (binary: yes or no) \n",
    "18. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) \n",
    "19. activities - extra-curricular activities (binary: yes or no) \n",
    "20. nursery - attended nursery school (binary: yes or no) \n",
    "21. higher - wants to take higher education (binary: yes or no) \n",
    "22. internet - Internet access at home (binary: yes or no) \n",
    "23. romantic - with a romantic relationship (binary: yes or no) \n",
    "24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent) \n",
    "25. freetime - free time after school (numeric: from 1 - very low to 5 - very high) \n",
    "26. goout - going out with friends (numeric: from 1 - very low to 5 - very high) \n",
    "27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high) \n",
    "28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) \n",
    "29. health - current health status (numeric: from 1 - very bad to 5 - very good) \n",
    "30. absences - number of school absences (numeric: from 0 to 93) \n",
    "31. G1 - first period grade (numeric: from 0 to 20) \n",
    "31. G2 - second period grade (numeric: from 0 to 20) \n",
    "32. G3 - final grade (numeric: from 0 to 20, output target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask_searchcv as dcv\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client \n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files being read in with Dask are listed below. Here glob is being used to identify and group all of the files with student grade data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['students_math_class.csv', 'students_portuguese_class.csv']\n"
     ]
    }
   ],
   "source": [
    "#Printing the files found by glob\n",
    "print(glob.glob('stu*.csv'))\n",
    "\n",
    "#Read in data with dask\n",
    "df = dd.read_csv(glob.glob('stu*.csv'), sep=';') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model (Tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each machine learning model will use categorical and continuous variables to predict what the final grade for each student was. Prior to model building, the data will be preprocessed, scaled, and split into train and test. While the final predictive power of the models may not be very strong, this exercise is being done simply to showcase the functionality of the Dask package. \n",
    "\n",
    "To start, create a client. This command creates a local scheduler and worker, which manages resource allocation and computation execution. A deeper dive into the documentation for Dask can be found below...\n",
    "\n",
    "__Dask Client Documentation__: http://distributed.dask.org/en/latest/client.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a local Dask client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when defining the categorical columns, the 'Fedu' column was not included. This is because there are only two cases where the value is not 0, and thus it can create a constant column when splitting into train and test. Logic and process for id'ing this column as constant is commented out in the appendix of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mixture of types in 'arrays'. Falling back to scikit-learn.\n"
     ]
    }
   ],
   "source": [
    "#Read in data with dask\n",
    "df = dd.read_csv('students_math_class.csv', sep=';')\n",
    "\n",
    "#Define categorical columns\n",
    "cat_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Medu',\\\n",
    "            'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', \\\n",
    "            'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', \\\n",
    "            'internet', 'romantic']\n",
    "\n",
    "#Convert to string so dask.get_dummies recognizes as categorical\n",
    "cat_sub = df[cat_cols].astype(str)\n",
    "\n",
    "#Creating dummies for the categorical variables\n",
    "cat_dums = dd.get_dummies(cat_sub.categorize()).compute()\n",
    "\n",
    "#Define continous columns\n",
    "con_cols = ['age', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
    "con_sub = df[con_cols].astype('float64') #Convert to float for scaling purposes\n",
    "\n",
    "#Merge categorical and continuous data\n",
    "merge = dd.merge(con_sub, cat_dums, left_index=True, right_index=True)\n",
    "\n",
    "#Converting to dask arrays for use in dask_ml \n",
    "X = merge.values.compute() #Inputs\n",
    "y = df['G3'].values.astype(int).compute() #Target\n",
    "\n",
    "#Splitting into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "#Fit scaler on training data only! Transform both!\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[:, :len(con_cols)]) #Fitting scaler on training data\n",
    "X_train[:, :len(con_cols)] = scaler.transform(X_train[:, :len(con_cols)]) #Transforming train\n",
    "X_test[:, :len(con_cols)] = scaler.transform(X_test[:, :len(con_cols)]) #Transforming test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dask linear regression method, we fit the model on the training data and use it to predict the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value is: 0.13\n"
     ]
    }
   ],
   "source": [
    "#Fit dask linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Predict test values\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "#Evaluate accuracy of dask linear regression model\n",
    "print(\"The R-squared value is:\", round(r2_score(y_test, y_pred), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the dask client's ability parallelize sklearn models to run a grid search for the optimal values of a random forest regression model. This shows the how easily dask can be integrated into existing code to take advantage of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with parallel_backend('dask'):\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    param_grid = {'bootstrap': [True],\n",
    "    'max_depth': [5, 10, 25, 50],\n",
    "    'max_features': [2, 5, 10],\n",
    "    'min_samples_leaf': [3, 5, 10],\n",
    "    'min_samples_split': [3, 5, 10],\n",
    "    'n_estimators': [50, 100, 250, 500]}\n",
    "\n",
    "    # Create a based model\n",
    "    from sklearn.ensemble import RandomForestRegressor #NOTE THAT THIS IS A PURE sklearn METHOD!!!\n",
    "    rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 50,\n",
       " 'max_features': 10,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = dcv.GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value is: 0.23\n"
     ]
    }
   ],
   "source": [
    "#Use the grid-searched random forest regressor model to predict the output of the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "#Evaluate accuracy of dask linear regression model\n",
    "print(\"The R-squared value is:\", round(r2_score(y_test, y_pred), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dask KMeans clustering algorithm, we can specify the number clusters and predict which cluster future observations would fall in. This is a great example of dask's ability to parallelize unsupervised learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikes\\Anaconda3\\lib\\site-packages\\dask\\array\\top.py:698: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  contains = index in indices\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', copy_x=True, init='k-means||', init_max_iter=None,\n",
       "    max_iter=300, n_clusters=3, n_jobs=1, oversampling_factor=2,\n",
       "    precompute_distances='auto', random_state=0, tol=0.0001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.cluster import KMeans\n",
    "model = KMeans(n_clusters=3, random_state=0)\n",
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 1, 1, 1, 2, 2, 0, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 1, 2,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outputting the predicted clusters for the test data\n",
    "model.predict(X_test).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dask, we were able to run methods with delayed execution, read and concatenate multiple files at once, utilize the dask ml library for linear regression and KMeans models, parallelize the existing sklearn random forest regressor model, and use dask grid search to identify best parameters. I hope you found this content useful, and best of luck using these tools in future analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Constant Column Identification and Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants = pd.DataFrame(X_train)\n",
    "# constants.head()\n",
    "# constant_cols = constants.max(axis=0) == constants.min(axis=0)\n",
    "# constant_cols.sum()\n",
    "# #27- (8 continous columns)  means access categorical column 19\n",
    "# cat_dums.iloc[:, 19].value_counts()\n",
    "# constant_cols.loc[constant_cols == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
